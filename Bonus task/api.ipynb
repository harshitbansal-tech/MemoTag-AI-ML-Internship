{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a986b-7e24-4db4-9dbf-0f187fcae7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import librosa\n",
    "import whisper\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import numpy as np\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.responses import JSONResponse\n",
    "from transformers import pipeline\n",
    "from langdetect import detect\n",
    "from yake import KeywordExtractor\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151c2fd-2715-43b1-aaea-b4675d733a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "emotion_pipeline = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", top_k=1)\n",
    "keyword_extractor = KeywordExtractor()\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44fb36e-5bea-4d00-a6ae-4da477e74fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "def extract_cognitive_features(text, audio, sr):\n",
    "    words = word_tokenize(text.lower())\n",
    "    hesitations = sum(1 for w in words if w in ['uh', 'um', 'hmm', 'er', 'ah'])\n",
    "    sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "    pauses_per_sentence = round(audio.tolist().count(0) / max(len(sentences), 1), 2)\n",
    "    \n",
    "    speech_rate = round(len(words) / (len(audio) / sr), 2)  # words per second\n",
    "    pitch = librosa.yin(audio, fmin=75, fmax=300)\n",
    "    pitch_var = round(np.std(pitch), 2)\n",
    "\n",
    "    return {\n",
    "        \"num_sentences\": len(sentences),\n",
    "        \"num_words\": len(words),\n",
    "        \"speech_rate_wps\": speech_rate,\n",
    "        \"pauses_per_sentence\": pauses_per_sentence,\n",
    "        \"hesitation_count\": hesitations,\n",
    "        \"pitch_variability\": pitch_var\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5cdcf5-440a-4eeb-9ec6-7fa801462bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_recall_issues(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    nouns = [word for word, tag in pos_tags if tag.startswith(\"NN\")]\n",
    "    keywords = [kw[0] for kw in keyword_extractor.extract_keywords(text)[:5]]\n",
    "    missing_keywords = [kw for kw in keywords if kw not in nouns]\n",
    "    return {\n",
    "        \"important_keywords\": keywords,\n",
    "        \"missing_keywords\": missing_keywords\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b2ceb-ae40-424e-be54-4bde6cefa584",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/analyze-cognition/\")\n",
    "async def analyze_cognition(file: UploadFile = File(...)):\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp:\n",
    "        tmp.write(await file.read())\n",
    "        tmp_path = tmp.name\n",
    "\n",
    "    y, sr = librosa.load(tmp_path, sr=None)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    result = whisper_model.transcribe(tmp_path)\n",
    "    text = result[\"text\"]\n",
    "\n",
    "    lang = detect(text)\n",
    "    sentiment = sentiment_pipeline(text)\n",
    "    emotion = emotion_pipeline(text)\n",
    "    embedding = embedder.encode([text])[0]\n",
    "\n",
    "    audio_features = extract_cognitive_features(text, y, sr)\n",
    "    recall_issues = detect_recall_issues(text)\n",
    "\n",
    "    os.remove(tmp_path)\n",
    "\n",
    "    return JSONResponse(content={\n",
    "        \"transcription\": text,\n",
    "        \"language\": lang,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"emotion\": emotion,\n",
    "        \"duration_sec\": round(duration, 2),\n",
    "        \"cognitive_features\": audio_features,\n",
    "        \"recall_issues\": recall_issues,\n",
    "        \"text_embedding\": embedding.tolist()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645844d4-1a73-482d-a45d-f8acb4778a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_api():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
